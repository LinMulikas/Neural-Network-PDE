{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss = 0.0088178292, lr = 0.001.\n",
      "- Best dict saved at epoch 1.\n",
      "  With best loss: 0.0088178292.\n",
      "\n",
      "Epoch 2, loss = 6.390627861, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 3, loss = 0.8878705502, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 4, loss = 2.8007137775, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 5, loss = 1.8664166927, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 6, loss = 1.2125401497, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 7, loss = 0.5344120264, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 8, loss = 0.212521553, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 9, loss = 0.7060028315, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 10, loss = 1.0385167599, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 11, loss = 0.7851165533, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 12, loss = 0.3778830767, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 13, loss = 0.2503563464, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 14, loss = 0.3799791336, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 15, loss = 0.4551713467, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 16, loss = 0.3411620855, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 17, loss = 0.1773461103, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 18, loss = 0.1361299753, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 19, loss = 0.2241525501, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 20, loss = 0.3127349019, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 21, loss = 0.303501159, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 22, loss = 0.2142882496, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 23, loss = 0.1300598979, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 24, loss = 0.1096534282, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 25, loss = 0.1397475004, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 26, loss = 0.1653764546, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 27, loss = 0.152133286, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 28, loss = 0.113369219, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 29, loss = 0.0862173587, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 30, loss = 0.091597043, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 31, loss = 0.1176862866, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 32, loss = 0.1364764869, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 33, loss = 0.1315057874, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 34, loss = 0.1098090336, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 35, loss = 0.0912124217, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 36, loss = 0.0886392295, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 37, loss = 0.0979307815, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 38, loss = 0.1047860831, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 39, loss = 0.0999458432, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 40, loss = 0.0871388614, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 41, loss = 0.0775101781, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 42, loss = 0.0780023187, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 43, loss = 0.0855203569, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 44, loss = 0.0913644955, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 45, loss = 0.0901040584, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 46, loss = 0.0839152411, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 47, loss = 0.0791296661, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 48, loss = 0.0794624686, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 49, loss = 0.0828355849, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 50, loss = 0.0843683407, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 51, loss = 0.0817282051, lr = 0.001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 52, loss = 0.0771470815, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 53, loss = 0.0745491683, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 54, loss = 0.0744896904, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 55, loss = 0.0744596571, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 56, loss = 0.0744507834, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 57, loss = 0.0744542778, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 58, loss = 0.0744618475, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 59, loss = 0.0744662732, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 60, loss = 0.0744623989, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 61, loss = 0.0744469166, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 62, loss = 0.0744187385, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 63, loss = 0.0743785948, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 64, loss = 0.0743286461, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 65, loss = 0.0742720068, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 66, loss = 0.0742121711, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 67, loss = 0.0741526037, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 68, loss = 0.0740962029, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 69, loss = 0.0740451068, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 70, loss = 0.0740005448, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 71, loss = 0.0739627555, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 72, loss = 0.0739311874, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 73, loss = 0.0739046633, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 74, loss = 0.0738815293, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 75, loss = 0.0738600865, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 76, loss = 0.0738386139, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 77, loss = 0.0738157928, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 78, loss = 0.0737906247, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 79, loss = 0.0737626255, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 80, loss = 0.0737316906, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 81, loss = 0.0736981928, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 82, loss = 0.0736626536, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 83, loss = 0.0736258328, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 84, loss = 0.0735884979, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 85, loss = 0.0735514015, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 86, loss = 0.0735149607, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 87, loss = 0.0734795928, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 88, loss = 0.0734453797, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 89, loss = 0.073412247, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 90, loss = 0.0733799487, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 91, loss = 0.0733481869, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 92, loss = 0.0733166337, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 93, loss = 0.073284924, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 94, loss = 0.0732528269, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 95, loss = 0.0732201487, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 96, loss = 0.0731868371, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 97, loss = 0.0731529221, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 98, loss = 0.0731185079, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 99, loss = 0.0730837286, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n",
      "Epoch 100, loss = 0.0730487704, lr = 0.0001.\n",
      "  Best loss: 0.0088178292 at epoch 1.\n"
     ]
    }
   ],
   "source": [
    "from HeatEq import *\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "net = PDENN(\n",
    "    input_size=2, output_size=1, hidden_depth=20, hidden_size=20, \n",
    "    lr = 1e-3)\n",
    "\n",
    "\n",
    "best_model = HeatEq((0, 1), (0, 1), 10000, load_best=True, net=net)\n",
    "best_model.drawReal(100, cmap='coolwarm')\n",
    "best_model.train(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
